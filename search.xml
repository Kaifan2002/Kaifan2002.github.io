<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>低光增强损失函数</title>
      <link href="/2025/12/28/lowlight-loss/"/>
      <url>/2025/12/28/lowlight-loss/</url>
      
        <content type="html"><![CDATA[<p>本文记载了在Low Light Image Enhancement （LLIE） 任务中常见的损失函数，并提供了相应的代码。其中的一些损失函数在其他Low Level任务中也可以适用。</p><h1 id="L1损失"><a href="#L1损失" class="headerlink" title="L1损失"></a>L1损失</h1><p>L1损失广泛应用在图像的各个任务中，<strong>L1损失</strong>（也称 <strong>Mean Absolute Error, MAE &#x2F; 平均绝对误差</strong>）是深度学习和统计回归中常见的一种损失函数。它通过计算预测值与真实值之间的 <strong>绝对差值</strong> 来衡量误差：</p><p>$$<br>\mathcal{L}<em>{L1} &#x3D; \frac{1}{N} \sum</em>{i&#x3D;1}^{N} \left| y_i - \hat{y}_i \right|<br>$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">Loss = nn.L1Loss() </span><br><span class="line"><span class="comment"># 或者</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">L1_loss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.loss = nn.L1Loss()</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, light_map, normal_img</span>):</span><br><span class="line">        loss = <span class="variable language_">self</span>.loss(light_map, normal_img)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="L2损失"><a href="#L2损失" class="headerlink" title="L2损失"></a>L2损失</h1><p>与L1损失一样，L2损失也是很常见的一种损失函数，但在低光增强任务中的应用比较少。L2 损失通过计算预测值与真实值之间 <strong>差值的平方</strong> 来度量误差：</p><p>$$<br>\mathcal{L}<em>{L2} &#x3D; \frac{1}{N} \sum</em>{i&#x3D;1}^{N} \left( y_i - \hat{y}_i \right)^2<br>$$</p><p> <strong>优点</strong>：</p><ul><li><strong>平滑收敛</strong>：平方会让小误差贡献更小，大误差贡献更大，梯度会逐渐减小，更利于优化。</li><li><strong>数学性质好</strong>：连续可导，优化器更容易收敛。<br><strong>缺点</strong>：</li><li><strong>对异常值敏感</strong>：如果样本中有 outlier，平方会放大其影响，模型容易偏向异常点。</li><li><strong>容易模糊</strong>（在图像任务中）：因为它倾向于最小化整体均方误差，导致预测结果趋向“平均值”，图像增强和生成中可能出现平滑&#x2F;模糊。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">criterion = nn.MSELoss() </span><br></pre></td></tr></table></figure><h1 id="VGG19损失函数——感知损失"><a href="#VGG19损失函数——感知损失" class="headerlink" title="VGG19损失函数——感知损失"></a>VGG19损失函数——感知损失</h1><p>感知损失（Perceptual Loss）是一种基于深度学习的图像风格迁移方法中常用的损失函数。与传统的均方误差损失函数（Mean Square Error，MSE）相比，感知损失更注重图像的感知质量，更符合人眼对图像质量的感受。<br>感知损失是通过预训练的神经网络来计算两张图片之间的差异。通常使用预训练的卷积神经网络（Convolutional Neural Network，CNN），这些网络已经在大规模的数据集上进行了训练，可以提取图像的高级特征。例如，VGG-19网络中的卷积层可以提取图像的纹理和结构信息，而网络的全连接层可以提取图像的语义信息。<br>感知损失的计算方式通常是将输入图像和目标图像分别通过预训练的神经网络，得到它们在网络中的特征表示。然后将这些特征表示作为损失函数的输入，计算它们之间的欧氏距离或曼哈顿距离。感知损失的目标是最小化输入图像和目标图像在特征空间的距离。<br>下面的代码实例化 了一个VGG19网络，并在VGGloss中调用该网络，分别输入增强后的图像和正常图像，输出各层调整计算L1&#x2F;L2损失。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VGG19</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, requires_grad=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        vgg_pretrained_features = torchvision.models.vgg19(weights=torchvision.models.VGG19_Weights.IMAGENET1K_V1).features</span><br><span class="line">        <span class="variable language_">self</span>.slice1 = torch.nn.Sequential()</span><br><span class="line">        <span class="variable language_">self</span>.slice2 = torch.nn.Sequential()</span><br><span class="line">        <span class="variable language_">self</span>.slice3 = torch.nn.Sequential()</span><br><span class="line">        <span class="variable language_">self</span>.slice4 = torch.nn.Sequential()</span><br><span class="line">        <span class="variable language_">self</span>.slice5 = torch.nn.Sequential()</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">            <span class="variable language_">self</span>.slice1.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">7</span>):</span><br><span class="line">            <span class="variable language_">self</span>.slice2.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7</span>, <span class="number">12</span>):</span><br><span class="line">            <span class="variable language_">self</span>.slice3.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>, <span class="number">21</span>):</span><br><span class="line">            <span class="variable language_">self</span>.slice4.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">21</span>, <span class="number">30</span>):</span><br><span class="line">            <span class="variable language_">self</span>.slice5.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> requires_grad:</span><br><span class="line">            <span class="keyword">for</span> param <span class="keyword">in</span> <span class="variable language_">self</span>.parameters():</span><br><span class="line">                param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        h_relu1 = <span class="variable language_">self</span>.slice1(X)</span><br><span class="line">        h_relu2 = <span class="variable language_">self</span>.slice2(h_relu1)</span><br><span class="line">        h_relu3 = <span class="variable language_">self</span>.slice3(h_relu2)</span><br><span class="line">        h_relu4 = <span class="variable language_">self</span>.slice4(h_relu3)</span><br><span class="line">        h_relu5 = <span class="variable language_">self</span>.slice5(h_relu4)</span><br><span class="line">        out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VGGLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, loss_weight=<span class="number">1.0</span>, criterion = <span class="string">&#x27;l1&#x27;</span>, reduction=<span class="string">&#x27;mean&#x27;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(VGGLoss, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.vgg = VGG19().cuda()</span><br><span class="line">        <span class="keyword">if</span> reduction <span class="keyword">not</span> <span class="keyword">in</span> [<span class="string">&#x27;none&#x27;</span>, <span class="string">&#x27;mean&#x27;</span>, <span class="string">&#x27;sum&#x27;</span>]:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&#x27;Unsupported reduction mode: <span class="subst">&#123;reduction&#125;</span>. &#x27;</span></span><br><span class="line">                             <span class="string">f&#x27;Supported ones are: <span class="subst">&#123;_reduction_modes&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> criterion == <span class="string">&#x27;l1&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.criterion = nn.L1Loss(reduction=reduction)</span><br><span class="line">        <span class="keyword">elif</span> criterion == <span class="string">&#x27;l2&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.criterion = nn.MSELoss(reduction=reduction)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError(<span class="string">&#x27;Unsupported criterion loss&#x27;</span>)</span><br><span class="line">      </span><br><span class="line">        <span class="variable language_">self</span>.weights = [<span class="number">1.0</span> / <span class="number">32</span>, <span class="number">1.0</span> / <span class="number">16</span>, <span class="number">1.0</span> / <span class="number">8</span>, <span class="number">1.0</span> / <span class="number">4</span>, <span class="number">1.0</span>]</span><br><span class="line">        <span class="variable language_">self</span>.weight = loss_weight</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        x_vgg, y_vgg = <span class="variable language_">self</span>.vgg(x), <span class="variable language_">self</span>.vgg(y)</span><br><span class="line">        loss = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x_vgg)):</span><br><span class="line">            loss += <span class="variable language_">self</span>.weights[i] * <span class="variable language_">self</span>.criterion(x_vgg[i], y_vgg[i].detach())</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.weight * loss</span><br></pre></td></tr></table></figure><p>另一种写法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line"><span class="comment"># other import</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> exp</span><br><span class="line"><span class="keyword">import</span> pytorch_msssim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MeanShift</span>(nn.Conv2d):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, rgb_range, rgb_mean, rgb_std, sign=-<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(MeanShift, <span class="variable language_">self</span>).__init__(<span class="number">3</span>, <span class="number">3</span>, kernel_size=<span class="number">1</span>)</span><br><span class="line">        std = torch.Tensor(rgb_std)</span><br><span class="line">        <span class="variable language_">self</span>.weight.data = torch.eye(<span class="number">3</span>).view(<span class="number">3</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        <span class="variable language_">self</span>.weight.data.div_(std.view(<span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="variable language_">self</span>.bias.data = sign * rgb_range * torch.Tensor(rgb_mean)</span><br><span class="line">        <span class="variable language_">self</span>.bias.data.div_(std)</span><br><span class="line">        <span class="variable language_">self</span>.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VGGLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, conv_index=<span class="string">&#x27;54&#x27;</span>, rgb_range=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(VGGLoss, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        vgg_features = models.vgg19(pretrained=<span class="literal">True</span>).features</span><br><span class="line">        modules = [m <span class="keyword">for</span> m <span class="keyword">in</span> vgg_features]</span><br><span class="line">        <span class="keyword">if</span> conv_index == <span class="string">&#x27;22&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.vgg = nn.Sequential(*modules[:<span class="number">8</span>])</span><br><span class="line">            <span class="variable language_">self</span>.vgg.cuda()</span><br><span class="line">        <span class="keyword">elif</span> conv_index == <span class="string">&#x27;54&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.vgg = nn.Sequential(*modules[:<span class="number">35</span>])</span><br><span class="line">            <span class="variable language_">self</span>.vgg.cuda()</span><br><span class="line"></span><br><span class="line">        vgg_mean = (<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>)</span><br><span class="line">        vgg_std = (<span class="number">0.229</span> * rgb_range, <span class="number">0.224</span> * rgb_range, <span class="number">0.225</span> * rgb_range)</span><br><span class="line">        <span class="variable language_">self</span>.sub_mean = MeanShift(rgb_range, vgg_mean, vgg_std).cuda()</span><br><span class="line">        <span class="variable language_">self</span>.vgg.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, sr, hr</span>):</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">_forward</span>(<span class="params">x</span>):</span><br><span class="line">            x = <span class="variable language_">self</span>.sub_mean(x)</span><br><span class="line">            x = <span class="variable language_">self</span>.vgg(x)</span><br><span class="line">            <span class="keyword">return</span> x</span><br><span class="line">          </span><br><span class="line">        vgg_sr = _forward(sr)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            vgg_hr = _forward(hr.detach())</span><br><span class="line"></span><br><span class="line">        loss = F.mse_loss(vgg_sr, vgg_hr)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>与一般的L1损失和L2损失对比，感知损失有以下特点：</p><table><thead><tr><th>特征</th><th>像素级损失(L1&#x2F;L2)</th><th>感知损失</th></tr></thead><tbody><tr><td>比较空间</td><td>原始像素空间</td><td>深度特征空间</td></tr><tr><td>关注点</td><td>像素值精确匹配</td><td>语义内容匹配</td></tr><tr><td>结果</td><td>可能模糊&#x2F;不自然</td><td>更自然、更符合视觉感知</td></tr><tr><td>计算复杂度</td><td>低</td><td>较高(需要前向传播)</td></tr></tbody></table><p>通常，感知损失是由L1损失和L2损失来计算的，表达式如下：</p><p>$$<br>\begin{equation}<br>\mathcal{L}<em>{\text{perceptual}}^{L1} &#x3D; \sum</em>{l} \lambda_l \left| \phi_l(I_{\text{gen}}) - \phi_l(I_{\text{ref}}) \right|_1<br>\end{equation}<br>$$</p><p>$$<br>\begin{equation}<br>\mathcal{L}<em>{\text{perceptual}}^{L2} &#x3D; \sum</em>{l} \lambda_l \left| \phi_l(I_{\text{gen}}) - \phi_l(I_{\text{ref}}) \right|_2^2<br>\end{equation}<br>$$</p><h1 id="边缘损失"><a href="#边缘损失" class="headerlink" title="边缘损失"></a>边缘损失</h1><p>边缘损失常用于低光增强、超分辨、去噪等重建类任务里。它的目标是让预测图像和真实图像在 边缘结构上尽量接近，从而避免结果模糊。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EdgeLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(EdgeLoss, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.sobel_kernel_x = torch.tensor([[-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>], [-<span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>], [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]], dtype=torch.float32).view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">        <span class="variable language_">self</span>.sobel_kernel_y = torch.tensor([[-<span class="number">1</span>, -<span class="number">2</span>, -<span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>]], dtype=torch.float32).view(<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, x_hat</span>):</span><br><span class="line">        <span class="variable language_">self</span>.sobel_kernel_x = <span class="variable language_">self</span>.sobel_kernel_x.to(x.device)</span><br><span class="line">        <span class="variable language_">self</span>.sobel_kernel_y = <span class="variable language_">self</span>.sobel_kernel_y.to(x.device)</span><br><span class="line">        grad_x = torch.zeros_like(x)</span><br><span class="line">        grad_x_hat = torch.zeros_like(x_hat)</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(x.shape[<span class="number">1</span>]):</span><br><span class="line">            grad_x_c_x = F.conv2d(x[:, c:c+<span class="number">1</span>, :, :], <span class="variable language_">self</span>.sobel_kernel_x, padding=<span class="number">1</span>)</span><br><span class="line">            grad_x_c_y = F.conv2d(x[:, c:c+<span class="number">1</span>, :, :], <span class="variable language_">self</span>.sobel_kernel_y, padding=<span class="number">1</span>)</span><br><span class="line">            grad_x[:, c:c+<span class="number">1</span>, :, :] = torch.sqrt(grad_x_c_x ** <span class="number">2</span> + grad_x_c_y ** <span class="number">2</span> + <span class="number">1e-6</span>)</span><br><span class="line">            grad_x_hat_c_x = F.conv2d(x_hat[:, c:c+<span class="number">1</span>, :, :], <span class="variable language_">self</span>.sobel_kernel_x, padding=<span class="number">1</span>)</span><br><span class="line">            grad_x_hat_c_y = F.conv2d(x_hat[:, c:c+<span class="number">1</span>, :, :], <span class="variable language_">self</span>.sobel_kernel_y, padding=<span class="number">1</span>)</span><br><span class="line">            grad_x_hat[:, c:c+<span class="number">1</span>, :, :] = torch.sqrt(grad_x_hat_c_x ** <span class="number">2</span> + grad_x_hat_c_y ** <span class="number">2</span> + <span class="number">1e-6</span>)</span><br><span class="line">        loss = F.mse_loss(grad_x, grad_x_hat)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h1 id="SSIM损失"><a href="#SSIM损失" class="headerlink" title="SSIM损失"></a>SSIM损失</h1><p>SSIM指标介于0到1直接，且越大说明模型效果越好，而SSIM损失就是：</p><p>$$<br>SSIM_{loss}&#x3D;1-SSIM<br>$$</p><p>SSIM的原理与具体计算方法不在这里展开</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SSIM_loss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, window_size=<span class="number">11</span>, sigma=<span class="number">1.5</span>, data_range=<span class="number">1.0</span>, channel=<span class="number">1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(SSIM_loss, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.window_size = window_size</span><br><span class="line">        <span class="variable language_">self</span>.sigma = sigma</span><br><span class="line">        <span class="variable language_">self</span>.data_range = data_range</span><br><span class="line">        <span class="variable language_">self</span>.channel = channel</span><br><span class="line">        <span class="variable language_">self</span>.gaussian_kernel = <span class="variable language_">self</span>._create_gaussian_kernel(window_size, sigma)</span><br><span class="line">      </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_create_gaussian_kernel</span>(<span class="params">self, window_size, sigma</span>):</span><br><span class="line">        gauss = torch.Tensor([np.exp(-(x - window_size//<span class="number">2</span>)**<span class="number">2</span>/<span class="built_in">float</span>(<span class="number">2</span>*sigma**<span class="number">2</span>)) </span><br><span class="line">                            <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(window_size)])</span><br><span class="line">        gauss = gauss / gauss.<span class="built_in">sum</span>()</span><br><span class="line">        kernel = torch.outer(gauss, gauss)</span><br><span class="line">        <span class="keyword">return</span> kernel.view(<span class="number">1</span>, <span class="number">1</span>, window_size, window_size).repeat(<span class="variable language_">self</span>.channel, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">ssim</span>(<span class="params">self, img1, img2</span>):</span><br><span class="line">        C1 = (<span class="number">0.01</span> * <span class="variable language_">self</span>.data_range)**<span class="number">2</span></span><br><span class="line">        C2 = (<span class="number">0.03</span> * <span class="variable language_">self</span>.data_range)**<span class="number">2</span></span><br><span class="line">        kernel = <span class="variable language_">self</span>.gaussian_kernel.to(img1.device)</span><br><span class="line">        mu1 = F.conv2d(img1, kernel, padding=<span class="number">0</span>, groups=<span class="variable language_">self</span>.channel)</span><br><span class="line">        mu2 = F.conv2d(img2, kernel, padding=<span class="number">0</span>, groups=<span class="variable language_">self</span>.channel)</span><br><span class="line">        mu1_sq = mu1.<span class="built_in">pow</span>(<span class="number">2</span>)</span><br><span class="line">        mu2_sq = mu2.<span class="built_in">pow</span>(<span class="number">2</span>)</span><br><span class="line">        mu1_mu2 = mu1 * mu2</span><br><span class="line">        sigma1_sq = F.conv2d(img1 * img1, kernel, padding=<span class="number">0</span>, groups=<span class="variable language_">self</span>.channel) - mu1_sq</span><br><span class="line">        sigma2_sq = F.conv2d(img2 * img2, kernel, padding=<span class="number">0</span>, groups=<span class="variable language_">self</span>.channel) - mu2_sq</span><br><span class="line">        sigma12 = F.conv2d(img1 * img2, kernel, padding=<span class="number">0</span>, groups=<span class="variable language_">self</span>.channel) - mu1_mu2</span><br><span class="line">        ssim_map = ((<span class="number">2</span> * mu1_mu2 + C1) * (<span class="number">2</span> * sigma12 + C2)) / \</span><br><span class="line">                  ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))</span><br><span class="line">      </span><br><span class="line">        <span class="keyword">return</span> ssim_map.mean()</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, img1, img2</span>):</span><br><span class="line">        <span class="keyword">if</span> img1.size() != img2.size():</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">f&quot;Input images must have the same dimensions. Got <span class="subst">&#123;img1.size()&#125;</span> and <span class="subst">&#123;img2.size()&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.channel != img1.shape[<span class="number">1</span>]:</span><br><span class="line">            <span class="variable language_">self</span>.channel = img1.shape[<span class="number">1</span>]</span><br><span class="line">            <span class="variable language_">self</span>.gaussian_kernel = <span class="variable language_">self</span>._create_gaussian_kernel(<span class="variable language_">self</span>.window_size, <span class="variable language_">self</span>.sigma)</span><br><span class="line">        ssim_val = <span class="variable language_">self</span>.ssim(img1, img2)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span> - ssim_val</span><br></pre></td></tr></table></figure><h1 id="频域损失"><a href="#频域损失" class="headerlink" title="频域损失"></a>频域损失</h1><p>随着频域处理引入低光增强领域，频域损失也在低光增强中得到应用，主要目的是让预测图与真值在 频率域的能量分布上保持一致</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FrequencyLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, loss_weight = <span class="number">0.01</span>, criterion =<span class="string">&#x27;l1&#x27;</span>, reduction = <span class="string">&#x27;mean&#x27;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(FrequencyLoss, <span class="variable language_">self</span>).__init__()   </span><br><span class="line">        <span class="variable language_">self</span>.loss_weight = loss_weight</span><br><span class="line">        <span class="variable language_">self</span>.reduction = reduction</span><br><span class="line">        <span class="keyword">if</span> criterion == <span class="string">&#x27;l1&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.criterion = nn.L1Loss(reduction=reduction)</span><br><span class="line">        <span class="keyword">elif</span> criterion == <span class="string">&#x27;l2&#x27;</span>:</span><br><span class="line">            <span class="variable language_">self</span>.criterion = nn.MSELoss(reduction=reduction)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError(<span class="string">&#x27;Unsupported criterion loss&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, pred, target, weight=<span class="literal">None</span>, **kwargs</span>):</span><br><span class="line">        pred_freq = <span class="variable language_">self</span>.get_fft_amplitude(pred)</span><br><span class="line">        target_freq = <span class="variable language_">self</span>.get_fft_amplitude(target)</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.loss_weight * <span class="variable language_">self</span>.criterion(pred_freq, target_freq)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_fft_amplitude</span>(<span class="params">self, inp</span>):</span><br><span class="line">        inp_freq = torch.fft.rfft2(inp, norm=<span class="string">&#x27;backward&#x27;</span>)</span><br><span class="line">        amp = torch.<span class="built_in">abs</span>(inp_freq)</span><br><span class="line">        <span class="keyword">return</span> amp</span><br></pre></td></tr></table></figure><h1 id="Charbonnier-Loss"><a href="#Charbonnier-Loss" class="headerlink" title="Charbonnier Loss"></a>Charbonnier Loss</h1><p>发表于《Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks》<br>与L1相比，增加了一个正则项。用Charbonnier Loss来近似L1损失来提高模型的性能,接近零点的值的梯度由于ε的存在，梯度不会太小，避免梯度消失。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">L1_Charbonnier_loss</span>(torch.nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;L1 Charbonnierloss.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(L1_Charbonnier_loss, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.eps = <span class="number">1e-6</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, Y</span>):</span><br><span class="line">        diff = torch.add(X, -Y)</span><br><span class="line">        error = torch.sqrt(diff * diff + <span class="variable language_">self</span>.eps)</span><br><span class="line">        loss = torch.mean(error)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h1 id="颜色一致性损失"><a href="#颜色一致性损失" class="headerlink" title="颜色一致性损失"></a>颜色一致性损失</h1><p>这里提到的颜色一致性损失是Zero-DCE模型中用到的一种损失，因此它不是一种监督学习中的损失函数，而是一种Zero-Shot中的损失函数。它在低光增强和图像复原任务中很常见，目的是约束增强后的图像保持合理的色彩平衡，避免增强结果出现明显的 偏色（例如全图偏红、偏绿）。该损失函数的原理为：在“<strong>灰世界假设 (Gray-World Assumption)</strong>”中，自然图像的 R&#x2F;G&#x2F;B 通道平均值应当接近一致。损失函数通过惩罚通道均值之间的差异，使得增强后的图像颜色更自然。<br>计算方式:</p><ul><li>先计算 RGB 三个通道的均值：$\mu_R,\mu_G,\mu_B$</li><li>计算通道差异：</li></ul><p>$$<br>D_{RG} &#x3D; (\mu_R - \mu_G)^2, \quad<br>D_{RB} &#x3D; (\mu_R - \mu_B)^2, \quad<br>D_{GB} &#x3D; (\mu_G - \mu_B)^2<br>$$</p><ul><li>计算颜色损失：<br>$$<br>\mathcal{L}<em>{color} &#x3D; \frac{1}{B} \sum</em>{b&#x3D;1}^{B}<br>\sqrt{ D_{RG}^{2} + D_{RB}^{2} + D_{GB}^{2} }<br>$$</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">L_color</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(L_color, <span class="variable language_">self</span>).__init__()</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x </span>):</span><br><span class="line">        b,c,h,w = x.shape</span><br><span class="line">        mean_rgb = torch.mean(x,[<span class="number">2</span>,<span class="number">3</span>],keepdim=<span class="literal">True</span>)</span><br><span class="line">        mr,mg, mb = torch.split(mean_rgb, <span class="number">1</span>, dim=<span class="number">1</span>)</span><br><span class="line">        Drg = torch.<span class="built_in">pow</span>(mr-mg,<span class="number">2</span>)</span><br><span class="line">        Drb = torch.<span class="built_in">pow</span>(mr-mb,<span class="number">2</span>)</span><br><span class="line">        Dgb = torch.<span class="built_in">pow</span>(mb-mg,<span class="number">2</span>)</span><br><span class="line">        k = torch.<span class="built_in">pow</span>(torch.<span class="built_in">pow</span>(Drg,<span class="number">2</span>) + torch.<span class="built_in">pow</span>(Drb,<span class="number">2</span>) + torch.<span class="built_in">pow</span>(Dgb,<span class="number">2</span>),<span class="number">0.5</span>)</span><br><span class="line">        <span class="keyword">return</span> k.mean()</span><br></pre></td></tr></table></figure><p>In the end:代码来源主要为主流低光增强模型的开源代码中，由于数量较多且各个模型所使用的损失函数多有重复，因此这里不再明确标注引用出处，对这些作者表示由衷感谢</p>]]></content>
      
      
      
        <tags>
            
            <tag> 低光增强 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/12/28/hello-world/"/>
      <url>/2025/12/28/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>fasterrcnn总结</title>
      <link href="/2025/04/16/fasterrcnn%E6%80%BB%E7%BB%93/"/>
      <url>/2025/04/16/fasterrcnn%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h1>FaterRCNN代码学习总结1</h1><h2>1.项目结构</h2>backbone为FaterRCNN主干网络部分的代码，包括其权重，此开源项目提供了VGG和resnet50两种，并提供了对应的权重文件，代码的作者认为backbone部分已经在coco数据集上训练完善了，因此在新的训练中可以直接调用coco数据集的权重文件作为权重初始化。data为自己创建的COCO数据格式的月球陨石坑数据集network_files为除backbone以外的结构部分，如roi_head、rpn_function和boxes、transform等对预测框和图像进行处理转换的脚本。save_weights为训练过程每一轮权重的存放目录train_utils是一个自定义的Python工具模块，主要包含训练过程中常用的辅助函数和工具类<p><img src="/images/fasterrcnn.jpg"></p><h2>2.train文件</h2><h3>2.1模块导入</h3><figure class="highlight plaintext"><figcaption><span>[lang:Python] import</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import datetime</span><br><span class="line">import torch</span><br><span class="line">from tqdm import tqdm  # 进度条显示库</span><br><span class="line">import transforms  # 数据预处理变换</span><br><span class="line">from network_files import FasterRCNN, FastRCNNPredictor  # 模型结构</span><br><span class="line">from backbone import resnet50_fpn_backbone  # 骨干网络</span><br><span class="line">from my_dataset import VOCDataSet  # VOC数据集读取(未使用)</span><br><span class="line">from datasets import CocoDataset  # COCO格式数据集读取</span><br><span class="line">from train_utils import GroupedBatchSampler, create_aspect_ratio_groups  # 数据采样工具</span><br><span class="line">from train_utils import train_eval_utils as utils  # 训练评估工具</span><br></pre></td></tr></table></figure><h3>2.2模型创建</h3>主要函数为def create_model(num_classes, load_pretrain_weights=True): 在该函数中调用backbone文件夹中的resnet50_fpn作为backbone ，之后使用FasterRCNN创建完整的model，导入预训练权重，更改roi_head中的分类头以适应自定义类别数，最后返回model（固定套路）。<figure class="highlight plaintext"><figcaption><span>[lang:Python] create_model</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def create_model(num_classes, load_pretrain_weights=True):</span><br><span class="line"> </span><br><span class="line">    backbone = resnet50_fpn_backbone(pretrain_path=&quot;/disk527/Commondisk/a804_qkf/vscodeproject/code/faster_rcnn/backbone/resnet50.pth&quot;,</span><br><span class="line">                                     norm_layer=torch.nn.BatchNorm2d,</span><br><span class="line">                                     trainable_layers=3)</span><br><span class="line">    # 训练自己数据集时不要修改这里的91，修改的是传入的num_classes参数</span><br><span class="line">    model = FasterRCNN(backbone=backbone, num_classes=91)</span><br><span class="line">    if load_pretrain_weights:</span><br><span class="line">        # 载入预训练模型权重</span><br><span class="line">        # https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth</span><br><span class="line">        weights_dict = torch.load(&quot;/disk527/Commondisk/a804_qkf/vscodeproject/code/faster_rcnn/backbone/fasterrcnn_resnet50_fpn_coco.pth&quot;, map_location=&#x27;cpu&#x27;)</span><br><span class="line">        missing_keys, unexpected_keys = model.load_state_dict(weights_dict, strict=False)</span><br><span class="line">        if len(missing_keys) != 0 or len(unexpected_keys) != 0:</span><br><span class="line">            print(&quot;missing_keys: &quot;, missing_keys)</span><br><span class="line">            print(&quot;unexpected_keys: &quot;, unexpected_keys)</span><br><span class="line">    # get number of input features for the classifier</span><br><span class="line">    in_features = model.roi_heads.box_predictor.cls_score.in_features</span><br><span class="line">    # replace the pre-trained head with a new one</span><br><span class="line">    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)</span><br><span class="line"> </span><br><span class="line">    return model</span><br></pre></td></tr></table></figure><h3>2.3主函数流程</h3><p>1.device 设备设置<br>2.data_transform &#x3D; 数据增强设置<br>3.文件初始化<br>4.train_datasets、val_datasets加载，通过dataset进行数据集加载<br>5.train_data_loader、val_data_loader进行批次划分加载，使用函数torch.utils.data.DataLoader<br>6.创建模型 model &#x3D; create_model(num_classes&#x3D;args.num_classes + 1)<br>7.model.to(device)<br>8.优化器设置，用到函数：torch.optim.选择需要的迭代器<br>9.学习率设置，用到函数：torch.optim.lr_scheduler.StepLR<br>10.恢复训练设置（接着上次训练结果继续训练，可有可无）</p><figure class="highlight plaintext"><figcaption><span>[lang:Python] train</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if args.resume != &quot;&quot;:</span><br><span class="line">        checkpoint = torch.load(args.resume, map_location=&#x27;cpu&#x27;)</span><br><span class="line">        model.load_state_dict(checkpoint[&#x27;model&#x27;])</span><br><span class="line">        optimizer.load_state_dict(checkpoint[&#x27;optimizer&#x27;])</span><br><span class="line">        lr_scheduler.load_state_dict(checkpoint[&#x27;lr_scheduler&#x27;])</span><br><span class="line">        args.start_epoch = checkpoint[&#x27;epoch&#x27;] + 1</span><br><span class="line">        if args.amp and &quot;scaler&quot; in checkpoint:</span><br><span class="line">            scaler.load_state_dict(checkpoint[&quot;scaler&quot;])</span><br><span class="line">        print(&quot;从epoch&#123;&#125;继续训练...&quot;.format(args.start_epoch))</span><br></pre></td></tr></table></figure><p>11.训练循环，主要针对train_loss、learning_rate、val_map进行更新，在循环前提前创建空列表，在循环中通过append进行记录，使用optimizer.step()进行参数更新</p><p>for epoch in tqdm(range(args.start_epoch, args.epochs), desc&#x3D;”总进度”):<br>        训练一个epoch： 使用函数utils.train_one_epoch（）；<br>        记录指标： .appeend() 主要针对train_loss、learning_rate、val_map进行记录；<br>        参数更新： lr_scheduler.step()；<br>        在验证集上评估：utils.evaluate（）；<br>        写入结果： with open；<br>        保存模型权重： 权重文件要用到torch.save函数，在调用权重文件时，对应的用torch.load函数，这两个函数相关联；<br>        循环结束<br>循环结束后，对训练过程的map loss 进行绘制</p><figure class="highlight plaintext"><figcaption><span>[lang:Python] plot_loss</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># plot loss and lr curve</span><br><span class="line">if len(train_loss) != 0 and len(learning_rate) != 0:</span><br><span class="line">    from plot_curve import plot_loss_and_lr</span><br><span class="line">    plot_loss_and_lr(train_loss, learning_rate)</span><br><span class="line"> </span><br><span class="line"># plot mAP curve</span><br><span class="line">if len(val_map) != 0:</span><br><span class="line">    from plot_curve import plot_map</span><br><span class="line">    plot_map(val_map)</span><br></pre></td></tr></table></figure><h3>2.4 train_one_epoch函数</h3>rain_one_epoch函数并不位于trian文件中，该作者将其放至在了下面的文件下，但在train文件中进行了调用。目录：faster_rcnn/train_utils/train_eval_utils.py。<figure class="highlight plaintext"><figcaption><span>[lang:Python] def</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def train_one_epoch(model, optimizer, data_loader, device, epoch,</span><br><span class="line">                    print_freq=50, warmup=False, scaler=None):</span><br></pre></td></tr></table></figure><p>执行一个完整的训练周期<br>    参数:<br>        model: 待训练的PyTorch模型<br>        optimizer: 优化器(如Adam&#x2F;SGD)<br>        data_loader: 训练数据加载器<br>        device: 计算设备(‘cuda’&#x2F;‘cpu’)<br>        epoch: 当前周期序号<br>        print_freq: 日志打印间隔(默认50个batch)<br>        warmup: 是否启用学习率预热(默认False)<br>        scaler: 混合精度训练的梯度缩放器(默认None)<br>1.初始化设置：设置为训练模式、指标记录器、添加学习率记录、日志头信息<br>2.warmup预热策略，避免训练初期因随机初始化导致梯度不稳定，逐步提高学习率</p><figure class="highlight plaintext"><figcaption><span>[lang:Python] warm</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if epoch == 0 and warmup is True:</span><br><span class="line">    warmup_factor = 1.0 / 1000  # 初始学习率缩放因子(从0.001倍开始)</span><br><span class="line">    warmup_iters = min(1000, len(data_loader) - 1)  # 预热步数(最多1000步)</span><br><span class="line">    lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)</span><br></pre></td></tr></table></figure><p>3.循环训练</p><figure class="highlight plaintext"><figcaption><span>[lang:Python] for</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i, [images, targets] in enumerate(metric_logger.log_every(data_loader, print_freq, header)):</span><br></pre></td></tr></table></figure><pre><code>数据转移到指定设备，使用.to(device)前向传播：model(images,targets)损失求和:：losses_reduced = sum(loss for loss in loss_dict_reduced.values())更新滑动平均损失检查损失是否有效反向传播与参数更新：清空梯度optimizer.zero_grad()、反向传播losses.backward() 、参数更新optimizer.step()、学习率更新lr_scheduler.step()记录指标</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Tmux--让服务器在后台继续干苦力</title>
      <link href="/2025/04/10/tmux/"/>
      <url>/2025/04/10/tmux/</url>
      
        <content type="html"><![CDATA[<p>Tmux是陈师兄介绍的方法，Tmux是一个终端复用器（terminal multiplexer），属于常用的开发工具，学会了之后可以大大的提高工作效率。<br>作为服务器窗口操作，主要可以用到的命令如下：（PS：本文作为笔者自己的笔记，感谢：<a href="https://blog.csdn.net/CSSDCC/article/details/121231906">https://blog.csdn.net/CSSDCC/article/details/121231906</a>  文章<br><img src="/images/loading.jpg"></p><ol><li>新建窗口 tmux new -s your-session-name</li><li>在tmux窗口中，按下ctrl+b d或者输入以下命令，就会将当前session与窗口分离，session转到后台执行  tmux detach</li><li>退出session tmux kill-session -t your-session-name 该命令会直接杀死窗口</li><li>切换窗口：<br>     ctrl+b c: 创建一个新窗口（状态栏会显示多个窗口的信息）<br>     ctrl+b p: 切换到上一个窗口（按照状态栏的顺序）<br>     ctrl+b n: 切换到下一个窗口<br>     ctrl+b w: 从列表中选择窗口（这个最好用）</li><li>使用快捷键ctrl+b [ ，就可以通过方向键上下移动使用PageUp和PageDown可以实现上下翻页</li><li>注意！！！不要乱用ctrl+c 容易导致窗口关闭</li><li>重新回到窗口tmux attach -t your-session-name </li><li>窗口重命名tmux rename-session -t old-session new-session</li><li>划分窗格：# 划分为上下两个窗格 tmux split-window<br>     # 划分左右两个窗格 tmux split-window -h<br>     左右划分：ctrl+b %<br>     上下划分：ctrl+b “</li><li>其他操作<br>列出所有快捷键，及其对应的 Tmux 命令： $ tmux list-keys<br>列出所有 Tmux 命令及其参数： $ tmux list-commands<br>列出当前所有 Tmux 会话的信息 ：$ tmux info<br>重新加载当前的 Tmux 配置： $ tmux source-file ~&#x2F;.tmux.conf</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>投影方式</title>
      <link href="/2025/04/08/%E6%8A%95%E5%BD%B1%E6%96%B9%E5%BC%8F/"/>
      <url>/2025/04/08/%E6%8A%95%E5%BD%B1%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>等距圆柱投影</p><p>等距圆柱投影方式如图所示：<br><img src="https://img2023.cnblogs.com/blog/981804/202306/981804-20230602142021107-871401001.png" alt="图片" title="等距圆柱投影示意图"><br><img src="https://img2023.cnblogs.com/blog/981804/202306/981804-20230602143153357-1081762523.png" alt="图片" title="等距圆柱投影示意图2"><br>等距圆柱投影（Equidistant Cylindrical Projection）是一种简单的地图投影方法，属于圆柱投影的一种。它的特点是保持经线和纬线均为等距的平行直线，形成规则的网格<br>基本特性<br>经纬线形状：<br>经线：等间隔的平行竖直线。</p><p>纬线：等间隔的平行水平线，与经线垂直。</p><p>网格呈矩形，类似棋盘。</p><p>等距性质：</p><p>沿经线方向：任意两条纬线之间的距离与实际地球表面相同（纬度间隔保持等距）。</p><p>沿纬线方向：赤道上的比例尺是真实的，但高纬度地区的东西方向会被拉伸（因纬线长度与实际不符）。</p><p>变形：</p><p>角度变形：所有纬线和经线的交点处角度保持不变（局部形状在小范围内近似），但整体地图存在显著的角度变形，尤其是高纬度地区。</p><p>面积变形：高纬度地区的面积会被夸大（例如极地地区显得异常大）。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 投影 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fist Blog</title>
      <link href="/2025/04/08/my-first-blog/"/>
      <url>/2025/04/08/my-first-blog/</url>
      
        <content type="html"><![CDATA[<p>先把甜甜放到第一位</p><p>邯郸学步，感谢陈师兄</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
