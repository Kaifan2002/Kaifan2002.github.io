<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>fasterrcnn总结</title>
      <link href="/2025/04/16/fasterrcnn%E6%80%BB%E7%BB%93/"/>
      <url>/2025/04/16/fasterrcnn%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h1>FaterRCNN代码学习总结1</h1><h2>1.项目结构</h2>backbone为FaterRCNN主干网络部分的代码，包括其权重，此开源项目提供了VGG和resnet50两种，并提供了对应的权重文件，代码的作者认为backbone部分已经在coco数据集上训练完善了，因此在新的训练中可以直接调用coco数据集的权重文件作为权重初始化。data为自己创建的COCO数据格式的月球陨石坑数据集network_files为除backbone以外的结构部分，如roi_head、rpn_function和boxes、transform等对预测框和图像进行处理转换的脚本。save_weights为训练过程每一轮权重的存放目录train_utils是一个自定义的Python工具模块，主要包含训练过程中常用的辅助函数和工具类![](images/fasterrcnn.jpg)<h2>2.train文件</h2><h3>2.1模块导入</h3><figure class="highlight plaintext"><figcaption><span>[lang:Python] import</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import datetime</span><br><span class="line">import torch</span><br><span class="line">from tqdm import tqdm  # 进度条显示库</span><br><span class="line">import transforms  # 数据预处理变换</span><br><span class="line">from network_files import FasterRCNN, FastRCNNPredictor  # 模型结构</span><br><span class="line">from backbone import resnet50_fpn_backbone  # 骨干网络</span><br><span class="line">from my_dataset import VOCDataSet  # VOC数据集读取(未使用)</span><br><span class="line">from datasets import CocoDataset  # COCO格式数据集读取</span><br><span class="line">from train_utils import GroupedBatchSampler, create_aspect_ratio_groups  # 数据采样工具</span><br><span class="line">from train_utils import train_eval_utils as utils  # 训练评估工具</span><br></pre></td></tr></table></figure><h3>2.2模型创建</h3>主要函数为def create_model(num_classes, load_pretrain_weights=True): 在该函数中调用backbone文件夹中的resnet50_fpn作为backbone ，之后使用FasterRCNN创建完整的model，导入预训练权重，更改roi_head中的分类头以适应自定义类别数，最后返回model（固定套路）。<figure class="highlight plaintext"><figcaption><span>[lang:Python] create_model</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def create_model(num_classes, load_pretrain_weights=True):</span><br><span class="line"> </span><br><span class="line">    backbone = resnet50_fpn_backbone(pretrain_path=&quot;/disk527/Commondisk/a804_qkf/vscodeproject/code/faster_rcnn/backbone/resnet50.pth&quot;,</span><br><span class="line">                                     norm_layer=torch.nn.BatchNorm2d,</span><br><span class="line">                                     trainable_layers=3)</span><br><span class="line">    # 训练自己数据集时不要修改这里的91，修改的是传入的num_classes参数</span><br><span class="line">    model = FasterRCNN(backbone=backbone, num_classes=91)</span><br><span class="line">    if load_pretrain_weights:</span><br><span class="line">        # 载入预训练模型权重</span><br><span class="line">        # https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth</span><br><span class="line">        weights_dict = torch.load(&quot;/disk527/Commondisk/a804_qkf/vscodeproject/code/faster_rcnn/backbone/fasterrcnn_resnet50_fpn_coco.pth&quot;, map_location=&#x27;cpu&#x27;)</span><br><span class="line">        missing_keys, unexpected_keys = model.load_state_dict(weights_dict, strict=False)</span><br><span class="line">        if len(missing_keys) != 0 or len(unexpected_keys) != 0:</span><br><span class="line">            print(&quot;missing_keys: &quot;, missing_keys)</span><br><span class="line">            print(&quot;unexpected_keys: &quot;, unexpected_keys)</span><br><span class="line">    # get number of input features for the classifier</span><br><span class="line">    in_features = model.roi_heads.box_predictor.cls_score.in_features</span><br><span class="line">    # replace the pre-trained head with a new one</span><br><span class="line">    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)</span><br><span class="line"> </span><br><span class="line">    return model</span><br></pre></td></tr></table></figure><h3>2.3主函数流程</h3><p>1.device 设备设置<br>2.data_transform &#x3D; 数据增强设置<br>3.文件初始化<br>4.train_datasets、val_datasets加载，通过dataset进行数据集加载<br>5.train_data_loader、val_data_loader进行批次划分加载，使用函数torch.utils.data.DataLoader<br>6.创建模型 model &#x3D; create_model(num_classes&#x3D;args.num_classes + 1)<br>7.model.to(device)<br>8.优化器设置，用到函数：torch.optim.选择需要的迭代器<br>9.学习率设置，用到函数：torch.optim.lr_scheduler.StepLR<br>10.恢复训练设置（接着上次训练结果继续训练，可有可无）</p><figure class="highlight plaintext"><figcaption><span>[lang:Python] train</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if args.resume != &quot;&quot;:</span><br><span class="line">        checkpoint = torch.load(args.resume, map_location=&#x27;cpu&#x27;)</span><br><span class="line">        model.load_state_dict(checkpoint[&#x27;model&#x27;])</span><br><span class="line">        optimizer.load_state_dict(checkpoint[&#x27;optimizer&#x27;])</span><br><span class="line">        lr_scheduler.load_state_dict(checkpoint[&#x27;lr_scheduler&#x27;])</span><br><span class="line">        args.start_epoch = checkpoint[&#x27;epoch&#x27;] + 1</span><br><span class="line">        if args.amp and &quot;scaler&quot; in checkpoint:</span><br><span class="line">            scaler.load_state_dict(checkpoint[&quot;scaler&quot;])</span><br><span class="line">        print(&quot;从epoch&#123;&#125;继续训练...&quot;.format(args.start_epoch))</span><br></pre></td></tr></table></figure><p>11.训练循环，主要针对train_loss、learning_rate、val_map进行更新，在循环前提前创建空列表，在循环中通过append进行记录，使用optimizer.step()进行参数更新</p><p>for epoch in tqdm(range(args.start_epoch, args.epochs), desc&#x3D;”总进度”):<br>    训练一个epoch： 使用函数utils.train_one_epoch（）；<br>    记录指标： .appeend() 主要针对train_loss、learning_rate、val_map进行记录；<br>    参数更新： lr_scheduler.step()；<br>    在验证集上评估：utils.evaluate（）；<br>    写入结果： with open；<br>    保存模型权重： 权重文件要用到torch.save函数，在调用权重文件时，对应的用torch.load函数，这两个函数相关联；<br>循环结束<br>循环结束后，对训练过程的map loss 进行绘制</p><figure class="highlight plaintext"><figcaption><span>[lang:Python] plot_loss</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># plot loss and lr curve</span><br><span class="line">if len(train_loss) != 0 and len(learning_rate) != 0:</span><br><span class="line">    from plot_curve import plot_loss_and_lr</span><br><span class="line">    plot_loss_and_lr(train_loss, learning_rate)</span><br><span class="line"> </span><br><span class="line"># plot mAP curve</span><br><span class="line">if len(val_map) != 0:</span><br><span class="line">    from plot_curve import plot_map</span><br><span class="line">    plot_map(val_map)</span><br></pre></td></tr></table></figure><h3>2.4 train_one_epoch函数</h3>rain_one_epoch函数并不位于trian文件中，该作者将其放至在了下面的文件下，但在train文件中进行了调用。目录：faster_rcnn/train_utils/train_eval_utils.py。<figure class="highlight plaintext"><figcaption><span>[lang:Python] def</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def train_one_epoch(model, optimizer, data_loader, device, epoch,</span><br><span class="line">                    print_freq=50, warmup=False, scaler=None):</span><br></pre></td></tr></table></figure><p>执行一个完整的训练周期<br>    参数:<br>        model: 待训练的PyTorch模型<br>        optimizer: 优化器(如Adam&#x2F;SGD)<br>        data_loader: 训练数据加载器<br>        device: 计算设备(‘cuda’&#x2F;‘cpu’)<br>        epoch: 当前周期序号<br>        print_freq: 日志打印间隔(默认50个batch)<br>        warmup: 是否启用学习率预热(默认False)<br>        scaler: 混合精度训练的梯度缩放器(默认None)<br>1.初始化设置：设置为训练模式、指标记录器、添加学习率记录、日志头信息<br>2.warmup预热策略，避免训练初期因随机初始化导致梯度不稳定，逐步提高学习率</p><figure class="highlight plaintext"><figcaption><span>[lang:Python] warm</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">if epoch == 0 and warmup is True:</span><br><span class="line">    warmup_factor = 1.0 / 1000  # 初始学习率缩放因子(从0.001倍开始)</span><br><span class="line">    warmup_iters = min(1000, len(data_loader) - 1)  # 预热步数(最多1000步)</span><br><span class="line">    lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)</span><br></pre></td></tr></table></figure><p>3.循环训练</p><figure class="highlight plaintext"><figcaption><span>[lang:Python] for</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i, [images, targets] in enumerate(metric_logger.log_every(data_loader, print_freq, header)):</span><br></pre></td></tr></table></figure><pre><code>数据转移到指定设备，使用.to(device)前向传播：model(images,targets)损失求和:：losses_reduced = sum(loss for loss in loss_dict_reduced.values())更新滑动平均损失检查损失是否有效反向传播与参数更新：清空梯度optimizer.zero_grad()、反向传播losses.backward() 、参数更新optimizer.step()、学习率更新lr_scheduler.step()记录指标</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Tmux--让服务器在后台继续干苦力</title>
      <link href="/2025/04/10/tmux/"/>
      <url>/2025/04/10/tmux/</url>
      
        <content type="html"><![CDATA[<p>Tmux是陈师兄介绍的方法，Tmux是一个终端复用器（terminal multiplexer），属于常用的开发工具，学会了之后可以大大的提高工作效率。<br>作为服务器窗口操作，主要可以用到的命令如下：（PS：本文作为笔者自己的笔记，感谢：<a href="https://blog.csdn.net/CSSDCC/article/details/121231906">https://blog.csdn.net/CSSDCC/article/details/121231906</a>  文章<br><img src="/images/loading.jpg"></p><ol><li>新建窗口 tmux new -s your-session-name</li><li>在tmux窗口中，按下ctrl+b d或者输入以下命令，就会将当前session与窗口分离，session转到后台执行  tmux detach</li><li>退出session tmux kill-session -t your-session-name 该命令会直接杀死窗口</li><li>切换窗口：<br>     ctrl+b c: 创建一个新窗口（状态栏会显示多个窗口的信息）<br>     ctrl+b p: 切换到上一个窗口（按照状态栏的顺序）<br>     ctrl+b n: 切换到下一个窗口<br>     ctrl+b w: 从列表中选择窗口（这个最好用）</li><li>使用快捷键ctrl+b [ ，就可以通过方向键上下移动使用PageUp和PageDown可以实现上下翻页</li><li>注意！！！不要乱用ctrl+c 容易导致窗口关闭</li><li>重新回到窗口tmux attach -t your-session-name </li><li>窗口重命名tmux rename-session -t old-session new-session</li><li>划分窗格：# 划分为上下两个窗格 tmux split-window<br>     # 划分左右两个窗格 tmux split-window -h<br>     左右划分：ctrl+b %<br>     上下划分：ctrl+b “</li><li>其他操作<br>列出所有快捷键，及其对应的 Tmux 命令： $ tmux list-keys<br>列出所有 Tmux 命令及其参数： $ tmux list-commands<br>列出当前所有 Tmux 会话的信息 ：$ tmux info<br>重新加载当前的 Tmux 配置： $ tmux source-file ~&#x2F;.tmux.conf</li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>投影方式</title>
      <link href="/2025/04/08/%E6%8A%95%E5%BD%B1%E6%96%B9%E5%BC%8F/"/>
      <url>/2025/04/08/%E6%8A%95%E5%BD%B1%E6%96%B9%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<p>等距圆柱投影</p><p>等距圆柱投影方式如图所示：<br><img src="https://img2023.cnblogs.com/blog/981804/202306/981804-20230602142021107-871401001.png" alt="图片" title="等距圆柱投影示意图"><br><img src="https://img2023.cnblogs.com/blog/981804/202306/981804-20230602143153357-1081762523.png" alt="图片" title="等距圆柱投影示意图2"><br>等距圆柱投影（Equidistant Cylindrical Projection）是一种简单的地图投影方法，属于圆柱投影的一种。它的特点是保持经线和纬线均为等距的平行直线，形成规则的网格<br>基本特性<br>经纬线形状：<br>经线：等间隔的平行竖直线。</p><p>纬线：等间隔的平行水平线，与经线垂直。</p><p>网格呈矩形，类似棋盘。</p><p>等距性质：</p><p>沿经线方向：任意两条纬线之间的距离与实际地球表面相同（纬度间隔保持等距）。</p><p>沿纬线方向：赤道上的比例尺是真实的，但高纬度地区的东西方向会被拉伸（因纬线长度与实际不符）。</p><p>变形：</p><p>角度变形：所有纬线和经线的交点处角度保持不变（局部形状在小范围内近似），但整体地图存在显著的角度变形，尤其是高纬度地区。</p><p>面积变形：高纬度地区的面积会被夸大（例如极地地区显得异常大）。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 投影 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Fist Blog</title>
      <link href="/2025/04/08/my-first-blog/"/>
      <url>/2025/04/08/my-first-blog/</url>
      
        <content type="html"><![CDATA[<p>先把甜甜放到第一位</p><p>邯郸学步，感谢陈师兄</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/04/08/hello-world/"/>
      <url>/2025/04/08/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
